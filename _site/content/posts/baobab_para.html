<h1 id="motivation--introduction">Motivation &amp; Introduction</h1>
<p>Researchers at the University of Geneva may request access and use the high-performance computing (HPC) server of the University of Geneva, Baobab. This cluster is particularly well suited for massive parallel computations. There exist already different ressources to help the user that are listed at the end of this tutorial.
However, the documentation already provided can be challenging to grasp for a new user. The aim of this tutorial is therefore to provide a clear and concise introduction to the use of the HPC Cluster Baobab.</p>

<h1 id="parallelisation-and-optimal-scheduling">Parallelisation and optimal scheduling</h1>
<p>The <code class="highlighter-rouge">bash</code> script discussed in the previous tutorial “Baobab Hello World” (<a href="https://blog-dal.netlify.com/posts/baobab_hello_world/">here</a>) run the <code class="highlighter-rouge">R</code> script written below on one CPU in one node. There is therefore no parallelisation of the code. However, when each iteration on a given programm are independant, one can parallelise the code such that the run time is reduced. We will in this tutorial discuss both the notion of command parallelisation and parallelisation via <code class="highlighter-rouge">slurm</code>, how one should modify both scripts based on the type of parallelisation and how the code will be executed on Baobab.</p>

<h2 id="command-parallelisation">Command parallelisation</h2>
<p>One can parallelise his code by distributing calculations of independant iterations over <code class="highlighter-rouge">n</code> CPU in the same node. This is called command parallelisation. In order to do such, one must change both the <code class="highlighter-rouge">bash</code> and the <code class="highlighter-rouge">R</code> code. With reference to the codes presented in the tutorial “Baobab Hello World”, one must change both codes as such to parallelise the <code class="highlighter-rouge">R</code> code on <code class="highlighter-rouge">n</code> CPU. We will here consider <code class="highlighter-rouge">n</code> as 8. The <code class="highlighter-rouge">bash</code> code would therefore be written as such:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="c">#SBATCH --job-name=simu_R</span>
<span class="c">#SBATCH --ntasks-per-node=1</span>
<span class="c">#SBATCH --cpus-per-task=8</span>
<span class="c">#SBATCH --time=0:15:0</span>
<span class="c">#SBATCH --partition=debug-EL7</span>
<span class="c">#SBATCH --mail-type=ALL</span>
<span class="c">#SBATCH --mail-user=firstname.lastname@unige.ch</span>

module load GCC/8.2.0-2.31.1 OpenMPI/3.1.3 R/3.6.0

<span class="nv">INFILE</span><span class="o">=</span>simu.R
<span class="nv">OUTFILE</span><span class="o">=</span>report_simu.Rout

srun R CMD BATCH <span class="nv">$INFILE</span> <span class="nv">$OUTFILE</span>
</code></pre></div></div>
<p>The <code class="highlighter-rouge">R</code> code would be written as such, using the <code class="highlighter-rouge">%dopar%</code> operator instead of <code class="highlighter-rouge">%do%"</code> and importing library <code class="highlighter-rouge">doParallel</code>:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Load libraries</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">foreach</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">doParallel</span><span class="p">)</span><span class="w">

</span><span class="c1"># set the number of cores in the sbatch script</span><span class="w">
</span><span class="n">registerDoParallel</span><span class="p">(</span><span class="n">cores</span><span class="o">=</span><span class="n">Sys.getenv</span><span class="p">(</span><span class="s2">"SLURM_CPUS_PER_TASK"</span><span class="p">))</span><span class="w">

</span><span class="c1"># print the number of workers</span><span class="w">
</span><span class="n">getDoParWorkers</span><span class="p">()</span><span class="w">

</span><span class="c1">#Simulate population</span><span class="w">
</span><span class="n">mysd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">15</span><span class="w">
</span><span class="n">mymean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">50</span><span class="w">
</span><span class="n">pop</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="m">10e5</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mymean</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mysd</span><span class="p">)</span><span class="w">

</span><span class="c1">#Define nbr of iterations</span><span class="w">
</span><span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10e3</span><span class="w">
</span><span class="n">samplesize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="w">
</span><span class="n">myresults</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">foreach</span><span class="p">(</span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">icount</span><span class="p">(</span><span class="n">B</span><span class="p">),</span><span class="w"> </span><span class="n">.combine</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rbind</span><span class="p">)</span><span class="o">%dopar%</span><span class="p">{</span><span class="w">
  </span><span class="n">mysample</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="n">pop</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">samplesize</span><span class="p">)</span><span class="w">
  </span><span class="n">mean</span><span class="p">(</span><span class="n">mysample</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="c1">#Theoretical xbar variance</span><span class="w">
</span><span class="n">mysd</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">samplesize</span><span class="w">

</span><span class="c1">#Observed xbar variance</span><span class="w">
</span><span class="n">var</span><span class="p">(</span><span class="n">myresults</span><span class="p">[,</span><span class="m">1</span><span class="p">])</span><span class="w">

</span><span class="c1">#Save results</span><span class="w">
</span><span class="n">save</span><span class="p">(</span><span class="n">myresults</span><span class="p">,</span><span class="w"> </span><span class="s2">"xbar_simulation_results.rda"</span><span class="p">)</span><span class="w">

</span></code></pre></div></div>

<h2 id="notes-on-optimal-scheduling-with-slurm">Notes on optimal scheduling with <code class="highlighter-rouge">slurm</code></h2>

<ul>
  <li>Define <code class="highlighter-rouge">--time</code> at minimum considering the time required by your task. One can run a small number of iterations of a given task to get an estimate of the time required to run a simulation.</li>
  <li>You can list partitions in the parameter <code class="highlighter-rouge">--partition</code> such that your task has a higher probability of being executed earlier (i.e. <code class="highlighter-rouge">#SBATCH --partition=mono-EL7,parallel-EL7,bigmem-EL7,shared-EL7,mono-shared-EL7,shared-bigmem-EL7</code>).</li>
  <li>Note that by specifying such a combination of <code class="highlighter-rouge">--ntasks-per-node</code> and <code class="highlighter-rouge">--cpus-per-task</code> your task will be executed only when an available node with that ammount of CPU is available (as oposed to parallelisation via <code class="highlighter-rouge">slurm</code>).</li>
  <li>Be sure to specifiy the correct possible <code class="highlighter-rouge">--partition</code> considering the <code class="highlighter-rouge">--time</code> parameter indicated and the limitations of each partition. One can find Baobab partitions and limits documentation <a href="https://baobab.unige.ch/enduser/src/enduser/enduser.html">here</a>.</li>
</ul>

<h2 id="parallelisation-via-slurm">Parallelisation via <code class="highlighter-rouge">slurm</code></h2>

<p>To be done</p>

<h1 id="useful-ressources">Useful ressources</h1>

<ul>
  <li><a href="https://plone.unige.ch/distic/pub/hpc/baobab_en">What is Baobab</a></li>
  <li><a href="https://baobab.unige.ch/enduser/enduser.html">Baobab Documentation</a></li>
  <li><a href="https://slurm.schedmd.com/">Slurm Documentation</a></li>
  <li><a href="https://slurm.schedmd.com/SUG14/sched_tutorial.pdf">Slurm Scheduling for Optimal Responsiveness and Utilization</a></li>
</ul>
